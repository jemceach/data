# Create loop to lable spam indicator
indicator<-c()
for(i in 1:length(test_tm)){
indicator<-c(label,test_tm[[i]]$meta$spam)
}
# Combine corpora
test <- c(ham, spam)
# Review Labeling
spam_lable <- data.frame(unlist(meta(test, "spam")))
spam_lable
# Combine corpora
test <- c(ham, spam)
# Review Labeling
spam_lable <- data.frame(unlist(meta(test, "spam")))
table(spam_lable)
# Combine corpora
test <- c(ham, spam)
# Review Labeling
spam_label <- data.frame(unlist(meta(test, "spam")))
table(spam_label)
# Combine corpora
test <- c(ham, spam)
# Review Labeling
spam_id <- data.frame(unlist(meta(test, "spam")))
table(spam_id)
library(knitr)
library(kableExtra)
library(tidyverse)
library(tm) # Text mining package
library(SnowballC) # Word stemming package
library(RTextTools)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
# set working directory
setwd("../week10")
# create list of file names for reference
spam.files <- list.files("spam")
ham.files <- list.files("easy_ham")
# load corpus from directory into R memory
spam <- VCorpus(DirSource("spam"), readerControl = list(language = "en"))
ham <- VCorpus(DirSource("easy_ham"), readerControl = list(language = "en"))
spam
ham
# loop spam
for (i in 1:length(spam)){
meta(spam[[i]], "spam", "corpus") <- "1"
}
# loop ham
for (i in 1:length(ham)){
meta(ham[[i]], "spam", "corpus") <- "0"
}
# Combine corpora
test <- c(ham, spam)
# Review Labeling
spam_id <- data.frame(unlist(meta(test, "spam")))
table(spam_id)
meta(test[[1]])
strwrap(test[[1]]$content[1:20])
stop <- c("date", "deliveredto", "received", "subject", "localhost", "returnpath") #added stopwords
test_tm <- test %>%
tm_map(content_transformer(tolower)) %>% # transform to lower case
tm_map(content_transformer(function(x) gsub(x, pattern="\\S*\\.\\S*", replacement=" "))) %>%  #regex
tm_map(content_transformer(function(x) gsub(x, pattern="\\S*\\@\\S*", replacement=" "))) %>%  #regex
tm_map(content_transformer(removePunctuation)) %>% # remove punctuation
tm_map(content_transformer(removeNumbers)) %>% # remove numbers
tm_map(content_transformer(PlainTextDocument)) %>% # plain text
tm_map(content_transformer(function(x) removeWords(x, words = c(stop, stopwords("en"))))) %>% #stopwords
tm_map(stemDocument) %>% # stem document
tm_map(content_transformer(stripWhitespace)) # remove white space
test_dtm <- DocumentTermMatrix(test_tm)
kable(inspect(test_dtm), caption = 'Inspect Initial DTM', format = "html") %>%
kable_styling(bootstrap_options = "condensed", full_width = F, position = "left") %>%
row_spec(row = 0:0, background = "lightgrey") %>%
column_spec(column = 1, bold = T)
refine_test <- test_tm %>%
DocumentTermMatrix(control=list(wordLengths=c(4, 20))) %>%
removeSparseTerms(.95)
kable(inspect(refine_test), caption = 'Inspect Refined DTM', format = "html") %>%
kable_styling(bootstrap_options = "condensed", full_width = F, position = "left") %>%
row_spec(row = 0:0, background = "lightgrey") %>%
column_spec(column = 1, bold = T)
term_freq <- refine_test %>%
as.matrix %>%
colSums() %>%
sort(decreasing=TRUE)
kable(head(term_freq, 10))
terms <- data.frame(term=names(term_freq), frequency=term_freq)
plot <- ggplot(subset(terms, frequency>1000), aes(x = reorder(term, -frequency), y = frequency)) +
geom_bar(stat = "identity", fill='grey') +
theme(axis.text.x=element_text(angle=90, hjust=1)) +
labs(title = "Terms with Frequencies > 1000", x = "Term", "Frequency")
plot
# Create loop to lable spam indicator
indicator<-c()
for(i in 1:length(test_tm)){
indicator<-c(label,test_tm[[i]]$meta$spam)
}
# Create loop to lable spam indicator
indicator<-c()
for(i in 1:length(test_tm)){
indicator<-c(spam_id,test_tm[[i]]$meta$spam)
}
# randomize data and set up model container using 75% probability
set.seed(100)
probs<-runif(length(test_tm),0,1)
train<-which(probs<=.75)
test<-which(probs>.75)
# build container for model from DTM
N <- length(spamtype)
# Create loop to lable spam indicator
indicator<-c()
for(i in 1:length(test_tm)){
indicator<-c(spam_id,test_tm[[i]]$meta$spam)
}
# randomize data and set up model container using 75% probability
set.seed(100)
probs<-runif(length(test_tm),0,1)
train<-which(probs<=.75)
test<-which(probs>.75)
# build container for model from DTM
N <- length(spam_id)
container <- create_container(refine_test, labels = indicator, trainSize = train, testSize = test, virgin = FALSE)
# Create loop to lable spam indicator
indicator<-c()
for(i in 1:length(test_tm)){
indicator<-c(spam_id,test_tm[[i]]$meta$spam)
}
# randomize data and set up model container using 75% probability
set.seed(100)
probs<-runif(length(test_tm),0,1)
train<-which(probs<=.75)
test<-which(probs>.75)
# build container for model from DTM
N <- length(indicator)
container <- create_container(refine_test, labels = indicator, trainSize = train, testSize = test, virgin = FALSE)
# Create loop to lable spam indicator
indicator<-c()
for(i in 1:length(test_tm)){
indicator<-c(spam_id,test_tm[[i]]$meta$spam)
}
# randomize data and set up model container using 75% probability
set.seed(100)
probs<-runif(length(test_tm),0,1)
train<-which(probs<=.75)
test<-which(probs>.75)
# build container for model from DTM
container <- create_container(refine_test, labels = spam_id, trainSize = train, testSize = test, virgin = FALSE)
# Create loop to lable spam indicator
indicator<-c()
for(i in 1:length(test_tm)){
indicator<-c(indicator,test_tm[[i]]$meta$spam)
}
# randomize data and set up model container using 75% probability
set.seed(100)
probs <- runif(length(test_tm),0,1)
train <- which(probs<=.75)
test <- which(probs>.75)
# build container for model from DTM
container <- create_container(refine_test, labels = indicator, trainSize = train, testSize = test, virgin = FALSE)
# use container to train models
train_svm <- train_model(container, "SVM")
train_max <-train_model(container, "MAXENT")
# use trained models to classify new data
classify_svm <- classify_model(container, train_svm)
classify_max <-classify_model(container, train_max)
# view output
svm <- head(classify_svm, 10)
max <- head(classify_max, 10)
kable(svm, caption = 'SVM Model Output', format = "html") %>%
kable_styling(bootstrap_options = "condensed", full_width = F, position = "left") %>%
row_spec(row = 0:0, background = "lightgrey") %>%
column_spec(column = 1, bold = T)
kable(max, caption = 'Maxent Model Output', format = "html") %>%
kable_styling(bootstrap_options = "condensed", full_width = F, position = "left") %>%
row_spec(row = 0:0, background = "lightgrey") %>%
column_spec(column = 1, bold = T)
# Create loop to lable spam indicator
indicator<-c()
for(i in 1:length(test_tm)){
indicator<-c(indicator,test_tm[[i]]$meta$spam)
}
# randomize data and set up model container using 75% probability
set.seed(100)
probs <- runif(length(test_tm),0,1)
train <- which(probs<=.75)
test <- which(probs>.75)
# build container for model from DTM
container <- create_container(refine_test, labels = indicator, trainSize = train, testSize = test, virgin = FALSE)
# use container to train models
train_svm <- train_model(container, "SVM")
train_max <-train_model(container, "MAXENT")
# use trained models to classify new data
classify_svm <- classify_model(container, train_svm)
classify_max <-classify_model(container, train_max)
# view output
svm <- head(classify_svm, 10)
max <- head(classify_max, 10)
kable(svm, caption = 'SVM Model Output', format = "html") %>%
kable_styling(bootstrap_options = "condensed", full_width = F, position = "left") %>%
row_spec(row = 0:0, background = "lightgrey") %>%
column_spec(column = 1, bold = T)
kable(max, caption = 'Maxent Model Output', format = "html") %>%
kable_styling(bootstrap_options = "condensed", full_width = F, position = "left") %>%
column_spec(column = 1, bold = T)
# Combine corpora
set.seed(10)
test <- sample(c(ham, spam))
# Review Labeling
spam_id <- data.frame(unlist(meta(test, "spam")))
table(spam_id)
# HUMAN DEVELOPMENT INDEX (HDI)
suppressWarnings(library(rvest, quietly =TRUE))
suppressWarnings(library(dplyr, quietly =TRUE))
suppressWarnings(library(stringr, quietly =TRUE))
suppressWarnings(library(tidyr, quietly =TRUE))
suppressWarnings(library(dplyr, quietly =TRUE))
suppressWarnings(library(ggplot2, quietly =TRUE))
suppressWarnings(library(curl, quietly =TRUE))
try(setwd("poverty/"))
curl_download("http://hdr.undp.org/en/indicators/137506", "hdi.html")
hdi <- read_html("hdi.html")
getwd()
try(setwd("poverty/"))
try(setwd("/poverty"))
try(setwd("../poverty"))
try(setwd("../poverty/"))
try(setwd("poverty/.."))
getwd()
try(setwd("poverty/."))
try(setwd("poverty/"))
try(setwd("poverty/.."))
setwd(/poverty)
setwd("/poverty")
setwd("~/GitHub/the-next-billion-online")
setwd(/poverty)
setwd("/poverty")
View(hdi)
View(hdi)
OccProj <- xml_node(hdi, "table")
head(OccProj)
View(OccProj)
View(OccProj)
hdi <- read_xml("hdi.html")
try(setwd("poverty/"))
curl_download("http://hdr.undp.org/en/indicators/137506", "hdi.html")
hdi <- read_xml("hdi.html")
hdi <- read_xml("hdi.xml")
try(setwd("poverty/"))
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
curl_download("http://hdr.undp.org/en/indicators/137506", "hdi.html")
hdi <- read_html("hdi.html")
hdi <- readHTMLTable("hdi.html")
suppressWarnings(library(XML, quietly =TRUE))
hdi <- readHTMLTable("hdi.html")
View(hdi)
xml_attrs(hdi)[["xmlns:skos"]]
xml_attrs(hdi)
xml_child(hdi, 2)
hdi
xml_child(hdi, 1)
hdi
airline = "http://hdr.undp.org/en/indicators/137506"
airline.table = readHTMLTable(airline, header=T, which=1,stringsAsFactors=F)
suppressWarnings(library(XML, quietly =TRUE))
airline = "http://hdr.undp.org/en/indicators/137506"
airline.table = readHTMLTable(airline, header=T, which=1,stringsAsFactors=F)
htmlParse(airline)
airline.table = readHTMLTable(airline, header=T,stringsAsFactors=F)
View(airline.table)
View(airline.table)
- html("http://hdr.undp.org/en/indicators/137506")
Titles <- xml_text(
html_nodes(doc,
xpath="//td/a[starts-with(., 'Title:')]/../following-sibling::td[1]")
doc <- read_html("http://hdr.undp.org/en/indicators/137506")
Titles <- xml_text(
doc <- read_html("http://hdr.undp.org/en/indicators/137506")
# HUMAN DEVELOPMENT INDEX (HDI)
suppressWarnings(library(rvest, quietly =TRUE))
suppressWarnings(library(dplyr, quietly =TRUE))
suppressWarnings(library(stringr, quietly =TRUE))
suppressWarnings(library(tidyr, quietly =TRUE))
suppressWarnings(library(dplyr, quietly =TRUE))
suppressWarnings(library(ggplot2, quietly =TRUE))
suppressWarnings(library(curl, quietly =TRUE))
suppressWarnings(library(XML, quietly =TRUE))
try(setwd("poverty/"))
doc <- read_html("http://hdr.undp.org/en/indicators/137506")
Titles <- xml_text(
html_nodes(doc,
xpath="//td/a[starts-with(., 'Title:')]/../following-sibling::td[1]")
View(doc)
View(doc)
xml_attrs(xml_child(xml_child(doc, 1), 10))
xml_attrs(xml_child(doc, 1))[["profile"]]
xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(doc, 2), 2), 1), 1), 1), 1), 1), 1), 1), 1), 1), 1)
xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(doc, 2), 2), 1), 1), 1), 1), 1), 2), 1), 1)
xml_attrs(xml_child(xml_child(doc, 2), 3))
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
install.packages("v8")\
install.packages("V8")
library(V8)
#URL with js-rendered content to be scraped
link <- 'http://hdr.undp.org/en/indicators/137506'
#Read the html page content and extract all javascript codes that are inside a list
emailjs <- read_html(link) %>% html_nodes('li') %>% html_nodes('script') %>% html_text()
# Create a new v8 context
ct <- v8()
#parse the html content from the js output and print it as text
read_html(ct$eval(gsub('document.write','',emailjs))) %>%
html_text()
View(ct)
View(ct)
environment(ct[["get"]])
curl_download("http://hdr.undp.org/en/indicators/137506", "hdi.html")
hdi <- read_xml("hdi.html")
curl_download("http://hdr.undp.org/en/indicators/137506", "hdi.html")
hdi <- read_xml("hdi.html")
hdi <- read_html("hdi.html")
View(hdi)
View(hdi)
xml_attrs(xml_child(xml_child(hdi, 2), 1))[["id"]]
xml_child(xml_child(hdi, 2), 3)
xml_attrs(xml_child(xml_child(xml_child(xml_child(xml_child(hdi, 2), 3), 2), 1), 1))[["id"]]
xml_child(xml_child(xml_child(xml_child(xml_child(hdi, 2), 3), 2), 1), 2)
xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(hdi, 2), 3), 2), 1), 2), 1), 1), 1), 1), 1)
xml_attrs(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(hdi, 2), 3), 2), 1), 2), 1), 1), 1), 1), 5))[["id"]]
xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(hdi, 2), 3), 2), 1), 2), 1), 1), 1), 1), 6)
xml_attrs(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(xml_child(hdi, 2), 3), 2), 1), 2), 1), 1), 1), 1), 8))
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
curl_download("http://hdr.undp.org/en/indicators/137506", "hdi.xml")
hdi <- read_xml("hdi.xml")
hdi <- read_xml("hdi.xml", encoding =  encoding)
hdi <- read_xml("hdi.xml")
hdi <- read_html("hdi.xml")
str(hdi)
hdi %>% html_node("div")
test <- hdi %>% html_node("div")
View(test)
View(test)
hdi <- read_html("http://hdr.undp.org/en/indicators/137506", "hdi.xml")
View(hdi)
View(hdi)
test <- hdi %>% html_node("div")
View(test)
View(test)
hdi <- read_html("http://hdr.undp.org/en/indicators/137506")
hdi %>% html_node("div")
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
html_attr(hdi)
hdi %>% html_node("div")
hdi <- readHTMLTable("http://hdr.undp.org/en/indicators/137506")
hdi
hdi <- readHTMLList("http://hdr.undp.org/en/indicators/137506")
hdi
hdi <- htmlParse("http://hdr.undp.org/en/indicators/137506")
hdi
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
hdi <- html_text("http://hdr.undp.org/en/indicators/137506")
hdi %>% html_nodes() %>% html_text() %>% stri_split_lines() %>% .[[1]] -> js_lines
html_nodes(pg, xpath=".//script[contains(., 'Less than')]") %>%
html_text() %>%
stri_split_lines() %>%
.[[1]] -> js_lines
html_nodes(hdi, xpath=".//script[contains(., 'Less than')]") %>%
html_text() %>%
stri_split_lines() %>%
.[[1]] -> js_lines
hdi %>% html_nodes() %>% html_text() %>% stri_split_lines() %>% .[[1]] -> js_lines
hdi <- read_html("http://hdr.undp.org/en/indicators/137506")
hdi %>% html_nodes() %>% html_text() %>% stri_split_lines() %>% .[[1]] -> js_lines
hdi %>% html_nodes()
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
View(test)
View(test)
test <- html_nodes(hdi, xpath =" .//script"[contains((., 'Less than')]")
test <- html_nodes(hdi, xpath =" .//script"[contains(., 'Less than')]")
test <- html_nodes(hdi, xpath =".//script[contains(., 'Less than')]")
test <- html_nodes(hdi, xpath =".//script[contains(., 'Less than')]")
View(test)
View(test)
xml_attrs(xml_child(test, 1))[["href"]]
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
test
html_nodes(hdi, xpath=".//div") %>%
html_text() %>%
stri_split_lines() %>%
.[[1]] -> js_lines
suppressWarnings(library(stringr, quietly =TRUE))
html_nodes(hdi, xpath=".//div") %>%
html_text() %>%
stri_split_lines() %>%
.[[1]] -> js_lines
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
html_nodes("table")
html_nodes(hdi, "div")
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
html_attr("table")
html_attr("th")
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
install.packages("JSON")
install.packages("rjson")
suppressWarnings(library(JSON, quietly =TRUE))
suppressWarnings(library(rjson, quietly =TRUE))
hdi <- fromJSON("http://hdr.undp.org/en/indicators/137506")
install.packages("RJSONIO")
hdi <- fromJSON("http://hdr.undp.org/en/indicators/137506")
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
hdi <- fromJSON("http://hdr.undp.org/en/indicators/137506", simplify = TRUE)
curl_download("http://data.un.org/DocumentData.aspx?q=human+development+index&id=378", "hdi.xml")
hdi <- read_html("hdi.xml")
View(hdi)
View(hdi)
hdi <- read_html("hdi.xml")
View(hdi)
View(hdi)
curl_download("http://data.un.org/DocumentData.aspx?q=human+development+index&id=378", "hdi.html")
hdi <- read_html("hdi.html")
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
load("C:/Users/15082/AppData/Local/Packages/Microsoft.MicrosoftEdge_8wekyb3d8bbwe/TempState/Downloads/hdis (1).RData")
View(hdis)
View(hdis)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
hdi <- readLines("http://hdr.undp.org/en/indicators/137506")
hdi
f
# HUMAN DEVELOPMENT INDEX (HDI)
suppressWarnings(library(rvest, quietly =TRUE))
suppressWarnings(library(dplyr, quietly =TRUE))
suppressWarnings(library(stringr, quietly =TRUE))
suppressWarnings(library(tidyr, quietly =TRUE))
suppressWarnings(library(dplyr, quietly =TRUE))
suppressWarnings(library(ggplot2, quietly =TRUE))
suppressWarnings(library(curl, quietly =TRUE))
try(setwd("poverty/"))
hdi <- readLines("http://hdr.undp.org/en/indicators/137506")
hdi
hdi
table(hdi)
data.frame(hdi)
data.frame(hdi)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
hdi <- curl("http://hdr.undp.org/en/indicators/137506", "hdi.html")
hdi <- curl_download("http://hdr.undp.org/en/indicators/137506", "hdi.html")
curl_download("http://hdr.undp.org/en/indicators/137506", "hdi.html")
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
hdi <- read.csv("hdi.csv")
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
hdi <- read.csv("hdi.csv", header = FALSE)
hdi
head(hdi)
View(hdi)
View(hdi)
view(hdi)
View(hdi)
glimpse(hdi)
suppressWarnings(library(dplyr, quietly =TRUE))
glimpse(hdi)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
hdi <- read.csv("hdi.csv", header = FALSE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
source('~/GitHub/the-next-billion-online/poverty/hdi.R', echo=TRUE)
